
### 마르코프 프로세스

**강화학습**은 **순차적 의사결정 문제**를 푸는 **방법론**.

**순차적 의사결정 문제**<sup>Sequential decision making</sup>는 결국 **MDP**<sup>Markov Decision Process</sup> 라는 개념을 통해서 정확하게 표현할 수 있다.
$$MP \equiv (S, P)$$
- 상태의 집합 **S** <br>
	$S= \{s_0, s_1, s_2, s_3, s_4 \}$


- 전이 확률 행렬 **P** <br>
	: 전이 확률<sup>transition probability</sup> 는 상태 s 에서 다음 상태 s' 에 도착할 확률을 가리킨다. <br>
	$$P_{ss'}$$
- $P_{ss'}$ 의 조건부 확률 개념을 이용한 표현 방식 <br>
	$$P_{ss'} = \mathbb{P}[S_{t+1} = s'|S_t = s]$$
	전이 확률은 s 와 s'에 대하여 행렬의 형태로 표현할 수 있다.


### 마르코프 성질
마르코프 프로세스의 모든 상태<sup>state</sup>는 마르코프 성질<sup>Markov Property</sup>를 따른다.

$$\mathbb{P}[s_{t+1}|s_t] = \mathbb{P}[s_{t+1}|s_1, s_2,...,s_t]$$
" 미래는 오로지 현재에 의해 결정된다 "


- **마르코프한 상태** <sup>Markovian state</sup> <br>
	시스템의 다음 상태가 **오직 현재 상태**에 의해서만 결정될 때, 그 상태를 마르코프한 상태라고 합니다. 즉, 과거의 상태는 미래의 상태에 아무런 영향을 미치지 않는다는 의미입니다.
	
	ex) 
	- 체스
	- 바둑
	- **날씨:** 오늘 날씨가 맑으면 내일 비가 올 확률은 오늘 날씨에만 의존하며, 어제 날씨와는 무관합니다.
	- **주식 시장:** 주식 시장의 내일 주가는 오늘의 주가와 시장 상황에 의해 결정되며, 과거의 주가 변동은 직접적인 영향을 미치지 않습니다.
	- **랜덤워크:** 다음 위치는 현재 위치와 이동 방향에만 의존하며, 이전 위치는 고려하지 않습니다.


- 마르코프하지 않은 상태


### 마르코프 리워드 프로세스
Markov Reward Process
